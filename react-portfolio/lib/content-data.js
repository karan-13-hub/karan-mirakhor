// Auto-generated content data
export const contentData = {
  "publications": [
    {
      "title": "Belief-Guided Zero-Shot Coordination for Multi-Agent Systems",
      "authors": "Karan Mirakhor, Katia Sycara",
      "venue": "ICLR",
      "year": 2026,
      "link": "https://openreview.net/forum?id=jJvXNpvOdM",
      "content": "We propose a novel approach to zero-shot coordination in multi-agent systems by leveraging belief modeling and opponent adaptation. Our method enables agents to coordinate effectively with unseen partners by maintaining beliefs about their strategies and adapting accordingly. The approach demonstrates significant improvements in cooperative environments with partial observability.",
      "slug": "belief-guided-zero-shot"
    },
    {
      "title": "Strategic Deception in Multi-Agent Reinforcement Learning",
      "authors": "Karan Mirakhor, Katia Sycara, Prashant Doshi",
      "venue": "AAMAS",
      "year": 2025,
      "link": "https://example.com/paper2",
      "content": "This work explores the role of strategic deception in multi-agent reinforcement learning environments. We develop a framework for agents to learn when and how to deceive opponents while maintaining cooperation when beneficial. The approach shows improved performance in competitive scenarios with partial information.",
      "slug": "multi-agent-deception"
    },
    {
      "title": "Hierarchical Task Planning for Robotic Object Rearrangement under Partial Observability",
      "authors": "Karan Mirakhor, TCS Research Team",
      "venue": "ICRA",
      "year": 2024,
      "link": "https://example.com/paper3",
      "content": "We present a hierarchical approach to task planning for robotic object rearrangement in partially observable environments. The method combines high-level symbolic planning with low-level motion planning, enabling robots to handle uncertainty and adapt to changing environments. Experimental results show improved success rates in cluttered indoor scenarios.",
      "slug": "robotic-task-planning"
    }
  ],
  "projects": [
    {
      "title": "Just Imagine: Closed-Loop VLA for Long-Horizon Tasks",
      "link": "https://drive.google.com/presentation/d/1zFm-VuV9FV5P4Vt70gTIIagh_6zWmC2OEriu3IMXxfQ",
      "content": "Visual-language-action pipeline leveraging world models for imagination-driven reasoning. Learning dense proxy rewards from sparse human videos to guide actorâ€“critic control on Libero benchmark. This project explores how visual language models can be integrated with robotic control for complex manipulation tasks.",
      "slug": "just-imagine-vla"
    },
    {
      "title": "Multi-Agent Simulation Framework for Cooperative Robotics",
      "link": "https://github.com/karan-13-hub/multi-agent-sim",
      "content": "A comprehensive simulation framework for testing multi-agent reinforcement learning algorithms in cooperative robotic environments. Features include configurable agent behaviors, dynamic environment generation, and real-time visualization. Used for validating MARL algorithms before real-world deployment.",
      "slug": "multi-agent-simulation"
    },
    {
      "title": "Uncertainty Quantification in Deep Reinforcement Learning",
      "link": "https://github.com/karan-13-hub/uncertainty-rl",
      "content": "Development of uncertainty quantification methods for deep reinforcement learning agents operating in safety-critical environments. Implements ensemble-based uncertainty estimation and Bayesian neural networks for improved decision-making under uncertainty. Applied to autonomous vehicle control and robotic manipulation tasks.",
      "slug": "uncertainty-quantification"
    }
  ],
  "awards": [
    {
      "title": "Best Research Paper Award - TCS Research",
      "year": 2024,
      "content": "Recognized for outstanding contribution to robotic task planning research. The paper presented novel approaches to hierarchical planning under partial observability, with significant practical applications in service robotics.",
      "slug": "best-research-paper"
    },
    {
      "title": "JN Tata Endowment Scholarship",
      "year": 2024,
      "content": "Received for excellence in academic research and potential for doctoral study. This prestigious scholarship recognizes outstanding academic achievement and research potential in engineering and technology fields.",
      "slug": "jn-tata-scholarship"
    },
    {
      "title": "Program Gold Medal - IIIT Hyderabad",
      "year": 2023,
      "content": "Awarded for achieving the highest GPA in the Electronics and Communication Engineering program. This recognition highlights academic excellence and outstanding performance throughout the undergraduate program.",
      "slug": "program-gold-medal"
    }
  ],
  "hero": {
    "name": "Karan Mirakhor",
    "title": "Masters of Science (Research) in Robotics",
    "institution": "Robotics Institute, Carnegie Mellon University",
    "tagline": "Advancing multi-agent systems through belief modeling and strategic decision-making",
    "profile_initials": "KM",
    "profile_image": "profile.jpeg",
    "content": "## Social Links\n\n- **Google Scholar**: [https://scholar.google.com/citations?user=wpeFm64AAAAJ&hl=en](https://scholar.google.com/citations?user=wpeFm64AAAAJ&hl=en)\n- **GitHub**: [https://github.com/karan-13-hub](https://github.com/karan-13-hub)\n- **LinkedIn**: [https://www.linkedin.com/in/karan-mirakhor-b065b7142/](https://www.linkedin.com/in/karan-mirakhor-b065b7142/)\n- **CV**: [https://drive.google.com/file/d/1KMUiU1Ze_I2ZgC0N5dFkpX_ucFn5C_G5/view?usp=sharing](https://drive.google.com/file/d/1KMUiU1Ze_I2ZgC0N5dFkpX_ucFn5C_G5/view?usp=sharing)\n\n## Background Elements\n\n- Background pattern with gradient circles\n- Scroll down indicator with animated arrow\n- Profile image placeholder with initials"
  },
  "about": {
    "title": "About Me",
    "current_position": "Graduate Research Assistant at the Robotics Institute, Carnegie Mellon University",
    "advisor": "Prof. Katia Sycara",
    "previous_position": "Pre-doctoral Research Fellow at TCS Research, India",
    "education": "B.Tech (Honors) in Electronics and Communication Engineering from IIIT Hyderabad",
    "achievement": "Program Gold Medal for highest GPA",
    "content": "## About Me\n\nHello! Iâ€™m Karan Mirakhor, a second-year Master of Science (Research) student in Robotics (MSR) at the [Robotics Institute](https://www.ri.cmu.edu/), [Carnegie Mellon University](https://www.cmu.edu/).\nGraduate Research Assistant - [Advanced Agent Robotics Technology Lab](https://www.ri.cmu.edu/robotics-groups/advanced-agent-robotics-technology-lab/)\nAdvisor: [Prof. Katia Sycara](https://www.cs.cmu.edu/~sycara/)    \nMy research primarily focuses on Multi-Agent Reinforcement Learning (MARL). Specifically, my work is on:\n\n---\n\nðŸ§  Zero-shot Coordination in Cooperative MARL  \nDeveloping agents that can seamlessly collaborate with previously unseen partners without additional training.  \nSpecifically, I focus on offline-to-online training frameworks that leverage behavioral diversity in offline datasets and enable efficient online adaptation using belief models.\n\nðŸŽ­ Competitive MARL and Targeted Deception  \nDeveloping targeted deception strategies by leveraging higher-order opponent belief models and analyzing historical response patterns to identify and exploit individual behavioral vulnerabilities.\n\n---\n\n## Previous Research Experience\n\nðŸ“š Pre-doctoral Research Fellow â€” [TCS Research](https://www.tcs.com/research-and-innovation)  \nAdvisor: [Dr. Brojeshwar Bhowmick](https://scholar.google.co.in/citations?user=Eqf8NrEAAAAJ&hl=en)  \n\nExplored Task Planning for Indoor Object Rearrangement under partial observability (POMDP). Developed scalable graph-based scene representations, utilized Large Language Models (LLMs) for semantic object search, and applied Deep RL for efficient single and multi-room planning.\n\n---\n\nðŸŽ“ B.Tech (Honors) in Electronics and Communication Engineering (ECE) â€” [IIIT Hyderabad](https://www.iiit.ac.in/)  \nResearch Assistant, [Robotics Research Center](https://robotics.iiit.ac.in/)  \nAdvisor: [Dr. Harikumar Kandath](https://scholar.google.co.in/citations?user=5i1t_QgAAAAJ&hl=en)  \n\nWorked on aerial manipulator control using Control Barrier Lyapunov constraints within a Model Predictive Controller for safe and stable operation.\n\n---\n\n## ðŸ”­ Future Vision\n\nI am fascinated by how intelligent agents can learn structured, transferable policies that generalize across tasks, embodiments, and environments, moving toward autonomous systems capable of learning and reasoning like humans.  \n\nMy long-term goal is to develop generalist robot policies that unify learning, reasoning, and control, advancing adaptable embodied agents for diverse real-world tasks.\n\n---\n\n## â˜• Beyond Research\n\nOutside the lab, I enjoy â™Ÿï¸ Chess, ðŸ¸ Squash, and ðŸ“ Table Tennis tennis. Iâ€™m a dedicated â˜• coffee enthusiast who enjoys strategy both on and off the board.\n\n---\n\n## Research Statistics\n\n- **Years Research Experience**: 5+\n- **Years Job Experience**: 2+\n- **Publications & Patents**: 3+"
  },
  "contact": {
    "title": "Get In Touch",
    "description": "I'm always interested in discussing new research opportunities, collaborations, and innovative projects in AI and robotics.",
    "primary_cta": "Send me an email",
    "primary_cta_link": "mailto:karanmirakhor@gmail.com",
    "content": "## Contact Information\n\n### Email\n- **Type**: Email\n- **Value**: karanmirakhor@gmail.com\n- **Link**: mailto:karanmirakhor@gmail.com\n\n### Google Scholar\n- **Type**: Google Scholar\n- **Value**: View Profile\n- **Link**: https://scholar.google.com/citations?user=wpeFm64AAAAJ&hl=en\n\n### GitHub\n- **Type**: GitHub\n- **Value**: karan-13-hub\n- **Link**: https://github.com/karan-13-hub\n\n### LinkedIn\n- **Type**: LinkedIn\n- **Value**: Connect\n- **Link**: https://www.linkedin.com/in/karan-mirakhor-b065b7142/\n\n### CV\n- **Type**: CV\n- **Value**: Download\n- **Link**: https://drive.google.com/file/d/1KMUiU1Ze_I2ZgC0N5dFkpX_ucFn5C_G5/view?usp=sharing"
  },
  "interests": {
    "title": "Research Interests",
    "description": "My research focuses on advancing artificial intelligence through multi-agent systems, with particular emphasis on learning, adaptation, and strategic decision-making.",
    "content": "## Interest Areas\n\n### Multi-Agent Reinforcement Learning\n- **Description**: Cooperative and competitive learning in multi-agent systems\n- **Icon**: ðŸ¤–\n\n### Robotics\n- **Description**: Autonomous systems and robotic manipulation\n- **Icon**: ðŸ¦¾\n\n### Imitation Learning\n- **Description**: Learning from human demonstrations and expert behavior\n- **Icon**: ðŸ‘¥\n\n### Decision Making under Uncertainty\n- **Description**: Robust decision-making in partially observable environments\n- **Icon**: ðŸŽ¯\n\n### Deception in AI\n- **Description**: Strategic deception and adversarial behavior in AI systems\n- **Icon**: ðŸŽ­"
  },
  "navbar": {
    "title": "Navigation",
    "content": "## Navigation Items\n\n- **About**: #about\n- **Research**: #research\n- **Publications**: #publications\n- **Projects**: #projects\n- **Awards**: #awards\n- **Contact**: #contact\n\n## Mobile Menu\n- Responsive mobile menu with hamburger icon\n- Smooth scroll to sections\n- Auto-close on navigation"
  },
  "footer": {
    "copyright_text": "Â© 2024 Karan Mirakhor. All rights reserved.",
    "content": "## Social Links\n\n### Google Scholar\n- **Link**: https://scholar.google.com/citations?user=wpeFm64AAAAJ&hl=en\n- **Aria Label**: Google Scholar\n\n### GitHub\n- **Link**: https://github.com/karan-13-hub\n- **Aria Label**: GitHub\n\n### LinkedIn\n- **Link**: https://www.linkedin.com/in/karan-mirakhor-b065b7142/\n- **Aria Label**: LinkedIn\n\n## Footer Features\n- Dynamic year calculation\n- Hover animations\n- Responsive layout"
  }
};

export function getAllContent(type) {
  return contentData[type] || [];
}

export function getContentBySlug(type, slug) {
  const allContent = getAllContent(type);
  return allContent.find(item => item.slug === slug) || null;
}

export function getSectionContent(sectionName) {
  return contentData[sectionName] || null;
}
