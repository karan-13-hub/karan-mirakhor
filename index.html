<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="keywords" content="AI, Machine Learning, Robotics, Multi-Agent Systems, Reinforcement Learning"/><meta name="author" content="Karan Mirakhor"/><meta property="og:title" content="Karan Mirakhor - Research Portfolio"/><meta property="og:description" content="Graduate Researcher in Reinforcement Learning and Robotics at Carnegie Mellon University"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Karan Mirakhor - Research Portfolio"/><meta name="twitter:description" content="Graduate Researcher in Reinforcement Learning and Robotics at Carnegie Mellon University"/><link rel="icon" href="/favicon.ico"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="true"/><title>Karan Mirakhor - Research Portfolio</title><meta name="description" content="Graduate Researcher in Reinforcement Learning and Robotics at Carnegie Mellon University"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="icon" href="/favicon.ico"/><meta name="next-head-count" content="16"/><link rel="preload" href="/karan-mirakhor/static/css/e9e69c7219f0440e.css" as="style"/><link rel="stylesheet" href="/karan-mirakhor/static/css/e9e69c7219f0440e.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/karan-mirakhor/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/karan-mirakhor/static/chunks/webpack-62cf374d0e243055.js" defer=""></script><script src="/karan-mirakhor/static/chunks/framework-02398e00071ab346.js" defer=""></script><script src="/karan-mirakhor/static/chunks/main-1a56076923beba60.js" defer=""></script><script src="/karan-mirakhor/static/chunks/pages/_app-2f5ed480144c0cde.js" defer=""></script><script src="/karan-mirakhor/static/chunks/9f96d65d-4b4b53fe89d86bd7.js" defer=""></script><script src="/karan-mirakhor/static/chunks/264-04f9ad717ca24e12.js" defer=""></script><script src="/karan-mirakhor/static/chunks/pages/index-b266d8280885ff18.js" defer=""></script><script src="/karan-mirakhor/static/-Wx0pNcOoiJqK5nLC082r/_buildManifest.js" defer=""></script><script src="/karan-mirakhor/static/-Wx0pNcOoiJqK5nLC082r/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="min-h-screen bg-navy"><nav class="fixed top-0 left-0 right-0 z-50 transition-all duration-300 bg-transparent" style="transform:translateY(-100px) translateZ(0)"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex items-center justify-between h-16"><div class="flex-shrink-0"><span class="text-xl font-bold text-accent">KM</span></div><div class="hidden md:block"><div class="ml-10 flex items-baseline space-x-8"><button class="text-lightSlate hover:text-accent px-3 py-2 text-sm font-medium transition-colors duration-200">About</button><button class="text-lightSlate hover:text-accent px-3 py-2 text-sm font-medium transition-colors duration-200">Research</button><button class="text-lightSlate hover:text-accent px-3 py-2 text-sm font-medium transition-colors duration-200">Publications</button><button class="text-lightSlate hover:text-accent px-3 py-2 text-sm font-medium transition-colors duration-200">Projects</button><button class="text-lightSlate hover:text-accent px-3 py-2 text-sm font-medium transition-colors duration-200">Awards</button><button class="text-lightSlate hover:text-accent px-3 py-2 text-sm font-medium transition-colors duration-200">Contact</button></div></div><div class="md:hidden"><button class="text-lightSlate hover:text-accent p-2"><svg class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path></svg></button></div></div></div></nav><main><section class="min-h-screen flex items-center justify-center relative overflow-hidden"><div class="absolute inset-0 opacity-10"><div class="absolute top-1/4 left-1/4 w-64 h-64 bg-accent rounded-full blur-3xl"></div><div class="absolute bottom-1/4 right-1/4 w-96 h-96 bg-accent rounded-full blur-3xl"></div></div><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 text-center relative z-10"><div class="space-y-8" style="opacity:0;transform:translateY(30px) translateZ(0)"><div class="w-32 h-32 mx-auto rounded-full bg-gradient-to-br from-accent to-accent/50 flex items-center justify-center text-4xl font-bold text-navy" style="transform:scale(0) translateZ(0)">KM</div><div class="space-y-4" style="opacity:0;transform:translateY(20px) translateZ(0)"><h1 class="text-4xl md:text-6xl lg:text-7xl font-bold text-white">Karan Mirakhor</h1><p class="text-xl md:text-2xl lg:text-3xl text-accent font-medium">Masters of Science (Research) in Robotics<br/>Robotics Institute, Carnegie Mellon University</p><p class="text-lg md:text-xl text-lightSlate max-w-3xl mx-auto">Advancing multi-agent systems through belief modeling and strategic decision-making</p></div><div class="flex flex-wrap justify-center gap-6" style="opacity:0;transform:translateY(20px) translateZ(0)"><a href="https://scholar.google.com/citations?user=wpeFm64AAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer" class="flex items-center space-x-2 text-lightSlate hover:text-accent transition-colors duration-200"><svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"><path d="M5.242 13.769L0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269zM12 10a7 7 0 1 0 0 14 7 7 0 0 0 0-14z"></path></svg><span>Google Scholar</span></a><a href="https://github.com/karan-13-hub" target="_blank" rel="noopener noreferrer" class="flex items-center space-x-2 text-lightSlate hover:text-accent transition-colors duration-200"><svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg><span>GitHub</span></a><a href="https://www.linkedin.com/in/karan-mirakhor-b065b7142/" target="_blank" rel="noopener noreferrer" class="flex items-center space-x-2 text-lightSlate hover:text-accent transition-colors duration-200"><svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg><span>LinkedIn</span></a><a href="https://drive.google.com/file/d/1KMUiU1Ze_I2ZgC0N5dFkpX_ucFn5C_G5/view?usp=sharing" target="_blank" rel="noopener noreferrer" class="flex items-center space-x-2 text-lightSlate hover:text-accent transition-colors duration-200"><svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"><path d="M14,2H6A2,2 0 0,0 4,4V20A2,2 0 0,0 6,22H18A2,2 0 0,0 20,20V8L14,2M18,20H6V4H13V9H18V20Z"></path></svg><span>CV</span></a></div><div class="pt-8" style="opacity:0"><button class="text-accent hover:text-white transition-colors duration-200"><div class="flex flex-col items-center space-y-2"><span class="text-sm">Scroll Down</span><div><svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 14l-7 7m0 0l-7-7m7 7V3"></path></svg></div></div></button></div></div></div></section><section id="about" class="py-20 bg-lightNavy/30"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="max-w-4xl mx-auto text-center" style="opacity:0;transform:translateY(30px) translateZ(0)"><h2 class="section-title">About Me</h2><div class="w-24 h-1 bg-accent mx-auto mb-8"></div><div class="space-y-6 text-lg text-lightSlate leading-relaxed"><div><p>## Professional Background</p><p>I am a Graduate Research Assistant at the Robotics Institute, Carnegie Mellon University, advised by Prof. Katia Sycara.</p><p>My research explores multi-agent reinforcement learning (MARL) in cooperative and competitive environments, emphasizing belief modeling, opponent adaptation, and decision-making under uncertainty.</p><p>Previously, I was a Pre-doctoral Research Fellow at TCS Research, India, working on task planning for indoor object rearrangement under partial observability.</p><p>I hold a B.Tech (Honors) in Electronics and Communication Engineering from IIIT Hyderabad, where I received the Program Gold Medal for highest GPA.</p><p>## Research Statistics</p><p>- **Years Research Experience**: 3+
- **Publications**: 5+
- **Projects**: 10+</p></div></div><div class="grid grid-cols-1 md:grid-cols-3 gap-8 mt-16" style="opacity:0;transform:translateY(20px) translateZ(0)"><div class="text-center"><div class="text-3xl font-bold text-accent mb-2">3+</div><div class="text-lightSlate">Years Research Experience</div></div><div class="text-center"><div class="text-3xl font-bold text-accent mb-2">5+</div><div class="text-lightSlate">Publications</div></div><div class="text-center"><div class="text-3xl font-bold text-accent mb-2">10+</div><div class="text-lightSlate">Projects</div></div></div></div></div></section><section id="research" class="py-20"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="text-center mb-16" style="opacity:0;transform:translateY(30px) translateZ(0)"><h2 class="section-title">Research Interests</h2><div class="w-24 h-1 bg-accent mx-auto mb-8"></div><p class="text-lg text-lightSlate max-w-3xl mx-auto">My research focuses on advancing artificial intelligence through multi-agent systems, with particular emphasis on learning, adaptation, and strategic decision-making.</p></div><div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8" style="opacity:0;transform:translateY(30px) translateZ(0)"><div class="card group cursor-pointer"><div class="text-center"><div class="text-4xl mb-4 group-hover:scale-110 transition-transform duration-200">🤖</div><h3 class="text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200">Multi-Agent Reinforcement Learning</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Cooperative and competitive learning in multi-agent systems</p></div></div><div class="card group cursor-pointer"><div class="text-center"><div class="text-4xl mb-4 group-hover:scale-110 transition-transform duration-200">🦾</div><h3 class="text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200">Robotics</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Autonomous systems and robotic manipulation</p></div></div><div class="card group cursor-pointer"><div class="text-center"><div class="text-4xl mb-4 group-hover:scale-110 transition-transform duration-200">👥</div><h3 class="text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200">Imitation Learning</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Learning from human demonstrations and expert behavior</p></div></div><div class="card group cursor-pointer"><div class="text-center"><div class="text-4xl mb-4 group-hover:scale-110 transition-transform duration-200">🎯</div><h3 class="text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200">Decision Making under Uncertainty</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Robust decision-making in partially observable environments</p></div></div><div class="card group cursor-pointer"><div class="text-center"><div class="text-4xl mb-4 group-hover:scale-110 transition-transform duration-200">🎭</div><h3 class="text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200">Deception in AI</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Strategic deception and adversarial behavior in AI systems</p></div></div></div></div></section><section id="publications" class="py-20 bg-lightNavy/30"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="text-center mb-16" style="opacity:0;transform:translateY(30px) translateZ(0)"><h2 class="section-title">Publications</h2><div class="w-24 h-1 bg-accent mx-auto mb-8"></div><p class="text-lg text-lightSlate max-w-3xl mx-auto">My research contributions in multi-agent reinforcement learning, robotics, and AI systems.</p></div><div class="space-y-8" style="opacity:0;transform:translateY(30px) translateZ(0)"><div class="card group hover:border-accent transition-all duration-300" style="opacity:0;transform:translateX(-20px) translateZ(0)"><div class="flex flex-col lg:flex-row lg:items-start lg:justify-between gap-4"><div class="flex-1"><h3 class="text-xl font-semibold text-white mb-2 group-hover:text-accent transition-colors duration-200">Belief-Guided Zero-Shot Coordination for Multi-Agent Systems</h3><p class="text-lightSlate mb-3">Karan Mirakhor, Katia Sycara</p><div class="flex flex-wrap items-center gap-4 text-sm"><span class="bg-accent/20 text-accent px-3 py-1 rounded-full">ICLR<!-- --> <!-- -->2026</span></div><p class="text-lightSlate mt-4 leading-relaxed">We propose a novel approach to zero-shot coordination in multi-agent systems by leveraging belief modeling and opponent adaptation. Our method enables agents to coordinate effectively with unseen partners by maintaining beliefs about their strategies and adapting accordingly. The approach demonstrates significant improvements in cooperative environments with partial observability.</p></div><a href="https://openreview.net/forum?id=jJvXNpvOdM" target="_blank" rel="noopener noreferrer" class="btn-primary whitespace-nowrap self-start lg:self-center">Read Paper</a></div></div><div class="card group hover:border-accent transition-all duration-300" style="opacity:0;transform:translateX(-20px) translateZ(0)"><div class="flex flex-col lg:flex-row lg:items-start lg:justify-between gap-4"><div class="flex-1"><h3 class="text-xl font-semibold text-white mb-2 group-hover:text-accent transition-colors duration-200">Strategic Deception in Multi-Agent Reinforcement Learning</h3><p class="text-lightSlate mb-3">Karan Mirakhor, Katia Sycara, Prashant Doshi</p><div class="flex flex-wrap items-center gap-4 text-sm"><span class="bg-accent/20 text-accent px-3 py-1 rounded-full">AAMAS<!-- --> <!-- -->2025</span></div><p class="text-lightSlate mt-4 leading-relaxed">This work explores the role of strategic deception in multi-agent reinforcement learning environments. We develop a framework for agents to learn when and how to deceive opponents while maintaining cooperation when beneficial. The approach shows improved performance in competitive scenarios with partial information.</p></div><a href="https://example.com/paper2" target="_blank" rel="noopener noreferrer" class="btn-primary whitespace-nowrap self-start lg:self-center">Read Paper</a></div></div><div class="card group hover:border-accent transition-all duration-300" style="opacity:0;transform:translateX(-20px) translateZ(0)"><div class="flex flex-col lg:flex-row lg:items-start lg:justify-between gap-4"><div class="flex-1"><h3 class="text-xl font-semibold text-white mb-2 group-hover:text-accent transition-colors duration-200">Hierarchical Task Planning for Robotic Object Rearrangement under Partial Observability</h3><p class="text-lightSlate mb-3">Karan Mirakhor, TCS Research Team</p><div class="flex flex-wrap items-center gap-4 text-sm"><span class="bg-accent/20 text-accent px-3 py-1 rounded-full">ICRA<!-- --> <!-- -->2024</span></div><p class="text-lightSlate mt-4 leading-relaxed">We present a hierarchical approach to task planning for robotic object rearrangement in partially observable environments. The method combines high-level symbolic planning with low-level motion planning, enabling robots to handle uncertainty and adapt to changing environments. Experimental results show improved success rates in cluttered indoor scenarios.</p></div><a href="https://example.com/paper3" target="_blank" rel="noopener noreferrer" class="btn-primary whitespace-nowrap self-start lg:self-center">Read Paper</a></div></div></div></div></section><section id="projects" class="py-20"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="text-center mb-16" style="opacity:0;transform:translateY(30px) translateZ(0)"><h2 class="section-title">Projects</h2><div class="w-24 h-1 bg-accent mx-auto mb-8"></div><p class="text-lg text-lightSlate max-w-3xl mx-auto">Selected projects showcasing my work in AI, robotics, and multi-agent systems.</p></div><div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8" style="opacity:0;transform:translateY(30px) translateZ(0)"><div class="card group cursor-pointer" style="opacity:0;transform:translateY(20px) translateZ(0)"><div class="h-full flex flex-col"><h3 class="text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200">Just Imagine: Closed-Loop VLA for Long-Horizon Tasks</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200 flex-1">Visual-language-action pipeline leveraging world models for imagination-driven reasoning. Learning dense proxy rewards from sparse human videos to guide actor–critic control on Libero benchmark. This project explores how visual language models can be integrated with robotic control for complex manipulation tasks.</p><a href="https://drive.google.com/presentation/d/1zFm-VuV9FV5P4Vt70gTIIagh_6zWmC2OEriu3IMXxfQ" target="_blank" rel="noopener noreferrer" class="inline-flex items-center text-accent hover:text-white mt-4 transition-colors duration-200"><span class="mr-2">View Project</span><svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"></path></svg></a></div></div><div class="card group cursor-pointer" style="opacity:0;transform:translateY(20px) translateZ(0)"><div class="h-full flex flex-col"><h3 class="text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200">Multi-Agent Simulation Framework for Cooperative Robotics</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200 flex-1">A comprehensive simulation framework for testing multi-agent reinforcement learning algorithms in cooperative robotic environments. Features include configurable agent behaviors, dynamic environment generation, and real-time visualization. Used for validating MARL algorithms before real-world deployment.</p><a href="https://github.com/karan-13-hub/multi-agent-sim" target="_blank" rel="noopener noreferrer" class="inline-flex items-center text-accent hover:text-white mt-4 transition-colors duration-200"><span class="mr-2">View Project</span><svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"></path></svg></a></div></div><div class="card group cursor-pointer" style="opacity:0;transform:translateY(20px) translateZ(0)"><div class="h-full flex flex-col"><h3 class="text-xl font-semibold text-white mb-3 group-hover:text-accent transition-colors duration-200">Uncertainty Quantification in Deep Reinforcement Learning</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200 flex-1">Development of uncertainty quantification methods for deep reinforcement learning agents operating in safety-critical environments. Implements ensemble-based uncertainty estimation and Bayesian neural networks for improved decision-making under uncertainty. Applied to autonomous vehicle control and robotic manipulation tasks.</p><a href="https://github.com/karan-13-hub/uncertainty-rl" target="_blank" rel="noopener noreferrer" class="inline-flex items-center text-accent hover:text-white mt-4 transition-colors duration-200"><span class="mr-2">View Project</span><svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"></path></svg></a></div></div></div></div></section><section id="awards" class="py-20 bg-lightNavy/30"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="text-center mb-16" style="opacity:0;transform:translateY(30px) translateZ(0)"><h2 class="section-title">Awards &amp; Recognition</h2><div class="w-24 h-1 bg-accent mx-auto mb-8"></div><p class="text-lg text-lightSlate max-w-3xl mx-auto">Recognition for academic excellence and research contributions.</p></div><div class="max-w-4xl mx-auto" style="opacity:0;transform:translateY(30px) translateZ(0)"><div class="relative"><div class="absolute left-8 top-0 bottom-0 w-0.5 bg-accent/30"></div><div class="space-y-8"><div class="relative flex items-start" style="opacity:0;transform:translateX(-20px) translateZ(0)"><div class="absolute left-6 w-4 h-4 bg-accent rounded-full border-4 border-navy z-10"></div><div class="ml-16 bg-lightNavy p-6 rounded-lg border border-lightestNavy hover:border-accent transition-all duration-300 group"><div class="flex flex-col sm:flex-row sm:items-center sm:justify-between gap-4"><div class="flex-1"><h3 class="text-xl font-semibold text-white mb-2 group-hover:text-accent transition-colors duration-200">Best Research Paper Award - TCS Research</h3><div class="text-accent font-medium mb-3">2024</div><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Recognized for outstanding contribution to robotic task planning research. The paper presented novel approaches to hierarchical planning under partial observability, with significant practical applications in service robotics.</p></div></div></div></div><div class="relative flex items-start" style="opacity:0;transform:translateX(-20px) translateZ(0)"><div class="absolute left-6 w-4 h-4 bg-accent rounded-full border-4 border-navy z-10"></div><div class="ml-16 bg-lightNavy p-6 rounded-lg border border-lightestNavy hover:border-accent transition-all duration-300 group"><div class="flex flex-col sm:flex-row sm:items-center sm:justify-between gap-4"><div class="flex-1"><h3 class="text-xl font-semibold text-white mb-2 group-hover:text-accent transition-colors duration-200">JN Tata Endowment Scholarship</h3><div class="text-accent font-medium mb-3">2024</div><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Received for excellence in academic research and potential for doctoral study. This prestigious scholarship recognizes outstanding academic achievement and research potential in engineering and technology fields.</p></div></div></div></div><div class="relative flex items-start" style="opacity:0;transform:translateX(-20px) translateZ(0)"><div class="absolute left-6 w-4 h-4 bg-accent rounded-full border-4 border-navy z-10"></div><div class="ml-16 bg-lightNavy p-6 rounded-lg border border-lightestNavy hover:border-accent transition-all duration-300 group"><div class="flex flex-col sm:flex-row sm:items-center sm:justify-between gap-4"><div class="flex-1"><h3 class="text-xl font-semibold text-white mb-2 group-hover:text-accent transition-colors duration-200">Program Gold Medal - IIIT Hyderabad</h3><div class="text-accent font-medium mb-3">2023</div><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Awarded for achieving the highest GPA in the Electronics and Communication Engineering program. This recognition highlights academic excellence and outstanding performance throughout the undergraduate program.</p></div></div></div></div></div></div></div></div></section><section id="contact" class="py-20"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8"><div class="text-center mb-16" style="opacity:0;transform:translateY(30px) translateZ(0)"><h2 class="section-title">Get In Touch</h2><div class="w-24 h-1 bg-accent mx-auto mb-8"></div><p class="text-lg text-lightSlate max-w-3xl mx-auto">I&#x27;m always interested in discussing new research opportunities, collaborations, and innovative projects in AI and robotics.</p></div><div class="max-w-4xl mx-auto" style="opacity:0;transform:translateY(30px) translateZ(0)"><div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6"><a href="mailto:karanmirakhor@gmail.com" target="_blank" rel="noopener noreferrer" class="card group cursor-pointer text-center hover:border-accent transition-all duration-300"><div class="flex flex-col items-center space-y-4"><div class="text-accent group-hover:text-white transition-colors duration-200"><svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M3 8l7.89 4.26a2 2 0 002.22 0L21 8M5 19h14a2 2 0 002-2V7a2 2 0 00-2-2H5a2 2 0 00-2 2v10a2 2 0 002 2z"></path></svg></div><div><h3 class="text-lg font-semibold text-white group-hover:text-accent transition-colors duration-200">Email</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">karanmirakhor@gmail.com</p></div></div></a><a href="https://scholar.google.com/citations?user=wpeFm64AAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer" class="card group cursor-pointer text-center hover:border-accent transition-all duration-300"><div class="flex flex-col items-center space-y-4"><div class="text-accent group-hover:text-white transition-colors duration-200"><svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24"><path d="M5.242 13.769L0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269zM12 10a7 7 0 1 0 0 14 7 7 0 0 0 0-14z"></path></svg></div><div><h3 class="text-lg font-semibold text-white group-hover:text-accent transition-colors duration-200">Google Scholar</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">View Profile</p></div></div></a><a href="https://github.com/karan-13-hub" target="_blank" rel="noopener noreferrer" class="card group cursor-pointer text-center hover:border-accent transition-all duration-300"><div class="flex flex-col items-center space-y-4"><div class="text-accent group-hover:text-white transition-colors duration-200"><svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg></div><div><h3 class="text-lg font-semibold text-white group-hover:text-accent transition-colors duration-200">GitHub</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">karan-13-hub</p></div></div></a><a href="https://www.linkedin.com/in/karan-mirakhor-b065b7142/" target="_blank" rel="noopener noreferrer" class="card group cursor-pointer text-center hover:border-accent transition-all duration-300"><div class="flex flex-col items-center space-y-4"><div class="text-accent group-hover:text-white transition-colors duration-200"><svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg></div><div><h3 class="text-lg font-semibold text-white group-hover:text-accent transition-colors duration-200">LinkedIn</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Connect</p></div></div></a><a href="https://drive.google.com/file/d/1KMUiU1Ze_I2ZgC0N5dFkpX_ucFn5C_G5/view?usp=sharing" target="_blank" rel="noopener noreferrer" class="card group cursor-pointer text-center hover:border-accent transition-all duration-300"><div class="flex flex-col items-center space-y-4"><div class="text-accent group-hover:text-white transition-colors duration-200"><svg class="w-6 h-6" fill="currentColor" viewBox="0 0 24 24"><path d="M14,2H6A2,2 0 0,0 4,4V20A2,2 0 0,0 6,22H18A2,2 0 0,0 20,20V8L14,2M18,20H6V4H13V9H18V20Z"></path></svg></div><div><h3 class="text-lg font-semibold text-white group-hover:text-accent transition-colors duration-200">CV</h3><p class="text-lightSlate group-hover:text-lightestSlate transition-colors duration-200">Download</p></div></div></a></div><div class="text-center mt-12" style="opacity:0;transform:translateY(20px) translateZ(0)"><a href="mailto:karanmirakhor@gmail.com" class="btn-primary text-lg px-8 py-4">Send me an email</a></div></div></div></section></main><footer class="bg-navy border-t border-lightestNavy"><div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8"><div class="text-center" style="opacity:0;transform:translateY(20px) translateZ(0)"><div class="flex flex-col md:flex-row items-center justify-between space-y-4 md:space-y-0"><div class="text-lightSlate">© 2024 Karan Mirakhor. All rights reserved.</div><div class="flex items-center space-x-6"><a href="https://scholar.google.com/citations?user=wpeFm64AAAAJ&amp;hl=en" target="_blank" rel="noopener noreferrer" class="text-lightSlate hover:text-accent transition-colors duration-200" aria-label="Google Scholar"><svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"><path d="M5.242 13.769L0 9.5 12 0l12 9.5-5.242 4.269C17.548 11.249 14.978 9.5 12 9.5c-2.977 0-5.548 1.748-6.758 4.269zM12 10a7 7 0 1 0 0 14 7 7 0 0 0 0-14z"></path></svg></a><a href="https://github.com/karan-13-hub" target="_blank" rel="noopener noreferrer" class="text-lightSlate hover:text-accent transition-colors duration-200" aria-label="GitHub"><svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"></path></svg></a><a href="https://www.linkedin.com/in/karan-mirakhor-b065b7142/" target="_blank" rel="noopener noreferrer" class="text-lightSlate hover:text-accent transition-colors duration-200" aria-label="LinkedIn"><svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433c-1.144 0-2.063-.926-2.063-2.065 0-1.138.92-2.063 2.063-2.063 1.14 0 2.064.925 2.064 2.063 0 1.139-.925 2.065-2.064 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg></a></div></div></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/","query":{},"buildId":"-Wx0pNcOoiJqK5nLC082r","assetPrefix":"/karan-mirakhor","nextExport":true,"autoExport":true,"isFallback":false,"scriptLoader":[]}</script></body></html>